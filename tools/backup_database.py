#!/usr/bin/env python3
"""
üóÑÔ∏è MAIRA Database Backup System
Sistema completo de backup y restauraci√≥n de base de datos PostgreSQL

Caracter√≠sticas:
- Backup completo de esquema y datos
- Backup incremental
- Restauraci√≥n autom√°tica
- Verificaci√≥n de integridad
- Rotaci√≥n autom√°tica de backups
"""

import os
import sys
import psycopg2
import subprocess
import json
import datetime
import argparse
from pathlib import Path
from dotenv import load_dotenv

class MAIRADatabaseBackup:
    def __init__(self):
        """Inicializar sistema de backup"""
        self.setup_environment()
        self.backup_dir = Path("backups")
        self.backup_dir.mkdir(exist_ok=True)
        
    def setup_environment(self):
        """Configurar variables de entorno"""
        # Cargar variables desde archivos .env
        env_files = ['.env.development', '.env', '.env.local']
        for env_file in env_files:
            if os.path.exists(env_file):
                load_dotenv(env_file)
                print(f"üìÅ Cargado: {env_file}")
                break
        
        # Configurar conexi√≥n a BD
        self.DATABASE_URL = os.environ.get('DATABASE_URL')
        if self.DATABASE_URL:
            print("üîó Usando DATABASE_URL desde variables de entorno")
        else:
            # Construir URL desde variables individuales
            self.db_config = {
                'host': os.environ.get('DB_HOST', 'localhost'),
                'database': os.environ.get('DB_NAME', 'maira_db'),
                'user': os.environ.get('DB_USER', 'postgres'),
                'password': os.environ.get('DB_PASSWORD', ''),
                'port': os.environ.get('DB_PORT', '5432')
            }
            self.DATABASE_URL = f"postgresql://{self.db_config['user']}:{self.db_config['password']}@{self.db_config['host']}:{self.db_config['port']}/{self.db_config['database']}"
            print(f"üîó Usando configuraci√≥n manual: {self.db_config['user']}@{self.db_config['host']}")
    
    def create_backup(self, backup_type="full", description=""):
        """
        Crear backup de la base de datos
        
        Args:
            backup_type (str): "full", "schema_only", "data_only"
            description (str): Descripci√≥n del backup
        """
        timestamp = datetime.datetime.now().strftime("%Y%m%d_%H%M%S")
        backup_name = f"maira_backup_{backup_type}_{timestamp}"
        
        # Archivos de backup
        sql_file = self.backup_dir / f"{backup_name}.sql"
        json_file = self.backup_dir / f"{backup_name}_metadata.json"
        
        try:
            print(f"üîÑ Iniciando backup {backup_type}...")
            
            # Determinar opciones de pg_dump
            dump_options = []
            if backup_type == "schema_only":
                dump_options.append("--schema-only")
            elif backup_type == "data_only":
                dump_options.append("--data-only")
            
            # Ejecutar pg_dump
            cmd = [
                "pg_dump",
                self.DATABASE_URL,
                "--verbose",
                "--no-owner",
                "--no-privileges",
                "--format=plain",
                f"--file={sql_file}",
                *dump_options
            ]
            
            result = subprocess.run(cmd, capture_output=True, text=True)
            
            if result.returncode != 0:
                raise Exception(f"pg_dump fall√≥: {result.stderr}")
            
            # Crear metadatos del backup
            metadata = {
                "backup_name": backup_name,
                "timestamp": timestamp,
                "backup_type": backup_type,
                "description": description,
                "database_url": self.DATABASE_URL,
                "file_size": sql_file.stat().st_size,
                "tables_backed_up": self._get_table_list(),
                "pg_dump_version": self._get_pg_dump_version(),
                "created_by": "MAIRA Backup System v1.0"
            }
            
            # Guardar metadatos
            with open(json_file, 'w') as f:
                json.dump(metadata, f, indent=2, default=str)
            
            print(f"‚úÖ Backup completado:")
            print(f"   üìÑ SQL: {sql_file}")
            print(f"   üìã Metadatos: {json_file}")
            print(f"   üìä Tama√±o: {self._format_size(sql_file.stat().st_size)}")
            
            return {
                "success": True,
                "sql_file": str(sql_file),
                "metadata_file": str(json_file),
                "metadata": metadata
            }
            
        except Exception as e:
            print(f"‚ùå Error creando backup: {e}")
            return {"success": False, "error": str(e)}
    
    def restore_backup(self, backup_file, confirm=False):
        """
        Restaurar backup de la base de datos
        
        Args:
            backup_file (str): Ruta al archivo .sql de backup
            confirm (bool): Confirmar restauraci√≥n (PELIGROSO)
        """
        if not confirm:
            print("‚ö†Ô∏è  PELIGRO: La restauraci√≥n borrar√° todos los datos actuales!")
            print("   Use --confirm para proceder")
            return {"success": False, "error": "Confirmaci√≥n requerida"}
        
        try:
            backup_path = Path(backup_file)
            if not backup_path.exists():
                raise Exception(f"Archivo de backup no encontrado: {backup_file}")
            
            print(f"üîÑ Restaurando desde: {backup_path}")
            
            # Primero, crear backup de seguridad de los datos actuales
            safety_backup = self.create_backup("full", "Pre-restore safety backup")
            if safety_backup["success"]:
                print(f"üõ°Ô∏è  Backup de seguridad creado: {safety_backup['sql_file']}")
            
            # Ejecutar restauraci√≥n
            cmd = [
                "psql",
                self.DATABASE_URL,
                "--file", str(backup_path),
                "--verbose"
            ]
            
            result = subprocess.run(cmd, capture_output=True, text=True)
            
            if result.returncode != 0:
                raise Exception(f"Restauraci√≥n fall√≥: {result.stderr}")
            
            print("‚úÖ Restauraci√≥n completada exitosamente")
            
            return {"success": True, "safety_backup": safety_backup}
            
        except Exception as e:
            print(f"‚ùå Error restaurando backup: {e}")
            return {"success": False, "error": str(e)}
    
    def list_backups(self):
        """Listar todos los backups disponibles"""
        backups = []
        
        for sql_file in self.backup_dir.glob("*.sql"):
            metadata_file = sql_file.with_suffix("").with_suffix("_metadata.json")
            
            backup_info = {
                "sql_file": str(sql_file),
                "size": self._format_size(sql_file.stat().st_size),
                "created": datetime.datetime.fromtimestamp(sql_file.stat().st_mtime)
            }
            
            # Cargar metadatos si existen
            if metadata_file.exists():
                try:
                    with open(metadata_file) as f:
                        metadata = json.load(f)
                        backup_info.update(metadata)
                except:
                    pass
            
            backups.append(backup_info)
        
        # Ordenar por fecha
        backups.sort(key=lambda x: x.get("created", datetime.datetime.min), reverse=True)
        
        return backups
    
    def cleanup_old_backups(self, keep_days=30):
        """Limpiar backups antiguos"""
        cutoff_date = datetime.datetime.now() - datetime.timedelta(days=keep_days)
        removed = 0
        
        for backup_file in self.backup_dir.glob("*.sql"):
            file_date = datetime.datetime.fromtimestamp(backup_file.stat().st_mtime)
            
            if file_date < cutoff_date:
                # Eliminar archivo SQL y metadatos
                metadata_file = backup_file.with_suffix("").with_suffix("_metadata.json")
                
                backup_file.unlink()
                if metadata_file.exists():
                    metadata_file.unlink()
                
                removed += 1
                print(f"üóëÔ∏è  Eliminado: {backup_file.name}")
        
        print(f"‚úÖ Limpieza completada: {removed} backups eliminados")
        return removed
    
    def verify_backup(self, backup_file):
        """Verificar integridad de un backup"""
        try:
            backup_path = Path(backup_file)
            
            # Verificar que el archivo existe y no est√° vac√≠o
            if not backup_path.exists():
                return {"valid": False, "error": "Archivo no encontrado"}
            
            if backup_path.stat().st_size == 0:
                return {"valid": False, "error": "Archivo vac√≠o"}
            
            # Verificar que es SQL v√°lido (b√°sico)
            with open(backup_path) as f:
                content = f.read(1000)  # Primeros 1000 caracteres
                
                if "CREATE TABLE" not in content and "INSERT INTO" not in content:
                    return {"valid": False, "error": "No parece un backup de PostgreSQL v√°lido"}
            
            return {"valid": True, "size": self._format_size(backup_path.stat().st_size)}
            
        except Exception as e:
            return {"valid": False, "error": str(e)}
    
    def _get_table_list(self):
        """Obtener lista de tablas en la base de datos"""
        try:
            conn = psycopg2.connect(self.DATABASE_URL)
            cursor = conn.cursor()
            
            cursor.execute("""
                SELECT table_name 
                FROM information_schema.tables 
                WHERE table_schema = 'public'
                ORDER BY table_name;
            """)
            
            tables = [row[0] for row in cursor.fetchall()]
            conn.close()
            
            return tables
            
        except Exception as e:
            return [f"Error obteniendo tablas: {e}"]
    
    def _get_pg_dump_version(self):
        """Obtener versi√≥n de pg_dump"""
        try:
            result = subprocess.run(["pg_dump", "--version"], capture_output=True, text=True)
            return result.stdout.strip()
        except:
            return "Desconocida"
    
    def _format_size(self, size_bytes):
        """Formatear tama√±o en bytes a formato legible"""
        for unit in ['B', 'KB', 'MB', 'GB']:
            if size_bytes < 1024.0:
                return f"{size_bytes:.1f} {unit}"
            size_bytes /= 1024.0
        return f"{size_bytes:.1f} TB"


def main():
    """Funci√≥n principal CLI"""
    parser = argparse.ArgumentParser(description="üóÑÔ∏è MAIRA Database Backup System")
    
    subparsers = parser.add_subparsers(dest='command', help='Comandos disponibles')
    
    # Comando backup
    backup_parser = subparsers.add_parser('backup', help='Crear backup')
    backup_parser.add_argument('--type', choices=['full', 'schema_only', 'data_only'], 
                              default='full', help='Tipo de backup')
    backup_parser.add_argument('--description', default='', help='Descripci√≥n del backup')
    
    # Comando restore
    restore_parser = subparsers.add_parser('restore', help='Restaurar backup')
    restore_parser.add_argument('file', help='Archivo de backup a restaurar')
    restore_parser.add_argument('--confirm', action='store_true', 
                               help='Confirmar restauraci√≥n (BORRA DATOS ACTUALES)')
    
    # Comando list
    subparsers.add_parser('list', help='Listar backups')
    
    # Comando cleanup
    cleanup_parser = subparsers.add_parser('cleanup', help='Limpiar backups antiguos')
    cleanup_parser.add_argument('--days', type=int, default=30, 
                               help='D√≠as a mantener (default: 30)')
    
    # Comando verify
    verify_parser = subparsers.add_parser('verify', help='Verificar backup')
    verify_parser.add_argument('file', help='Archivo de backup a verificar')
    
    args = parser.parse_args()
    
    if not args.command:
        parser.print_help()
        return
    
    # Crear instancia del sistema de backup
    backup_system = MAIRADatabaseBackup()
    
    # Ejecutar comando
    if args.command == 'backup':
        result = backup_system.create_backup(args.type, args.description)
        if not result["success"]:
            sys.exit(1)
    
    elif args.command == 'restore':
        result = backup_system.restore_backup(args.file, args.confirm)
        if not result["success"]:
            sys.exit(1)
    
    elif args.command == 'list':
        backups = backup_system.list_backups()
        
        print(f"\nüìã Backups disponibles ({len(backups)}):")
        print("=" * 80)
        
        for backup in backups:
            print(f"üìÑ {backup.get('backup_name', 'Sin nombre')}")
            print(f"   Archivo: {backup['sql_file']}")
            print(f"   Tama√±o: {backup['size']}")
            print(f"   Tipo: {backup.get('backup_type', 'Desconocido')}")
            print(f"   Fecha: {backup['created']}")
            if backup.get('description'):
                print(f"   Descripci√≥n: {backup['description']}")
            print()
    
    elif args.command == 'cleanup':
        backup_system.cleanup_old_backups(args.days)
    
    elif args.command == 'verify':
        result = backup_system.verify_backup(args.file)
        if result["valid"]:
            print(f"‚úÖ Backup v√°lido - Tama√±o: {result['size']}")
        else:
            print(f"‚ùå Backup inv√°lido: {result['error']}")
            sys.exit(1)


if __name__ == "__main__":
    main()
